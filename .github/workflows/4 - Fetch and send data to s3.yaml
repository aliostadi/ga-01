name: 4 - Fetch and send data to s3

on:
  workflow_dispatch: 

jobs:
  fetch_data:
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout the repository
        uses: actions/checkout@v4

      - name: Install jq
        run: sudo apt-get install jq

      - name: Fetch data
        run: |
          TIMESTAMP=$(date +%s)
          OUTPUT_FILE="stage/${TIMESTAMP}.csv"
          mkdir -p stage
          curl -s -H "User-Agent: Chrome/123.0" https://www.sahamyab.com/guest/twiter/list?v=0.1 | jq '.items[] | [.id, .sendTime, .sendTimePersian, .senderName, .senderUsername, .type, .content] | join(",") ' > $OUTPUT_FILE
          echo "Data saved to $OUTPUT_FILE"

      - name: Commit and push changes
        run: |
          git config --local user.email "ali.ostadiy@gmail.com"
          git config --local user.name "aliostadi"
          git add stage/
          git commit -m "Fetch data at $(date)"
          git push
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}


  send-to-bucket: #it uploads the data to an object storage service (like AWS S3, MinIO, or Wasabi) using a Python script.
    runs-on: ubuntu-latest
    needs: fetch_data # üîÅ This job will only run *after* the 'fetch_data' job finishes successfully

    steps:
      - name: Checkout the repository
        uses: actions/checkout@v4

      - name: set up python
        uses: actions/setup-python@v5 # üêç GitHub official action to install a specific Python version
        with:
          python-version: '3.10' 
        
      - name: Install dependencies
        run: |
          pip install -r requirements.txt  
         
      - name: Run upload script
        run: |
          python send-to-object-storage.py

        env:
          ACCESS_KEY: ${{ secrets.S3_BUCKET_ACCESS_KEY }} #üîë Access key from GitHub Secrets
          SECRET_KEY: ${{ secrets.S3_BUCKET_SECRET_ACCESS_KEY }} 
